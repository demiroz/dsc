{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data in to inspect it\n",
    "with open ('/Users/SHSU/Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Springboard/dsc/Capstone Three/HC_DATA/medquad_qa_pairs.csv', 'r') as f:\n",
    "    df = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 22835185\n"
     ]
    }
   ],
   "source": [
    "print('length of dataset in characters:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question,answer,source,focus_area\n",
      "What is (are) Glaucoma ?,\"Glaucoma is a group of diseases that can damage the eye's optic nerve and result in vision loss and blindness. While glaucoma can strike anyone, the risk is much greater for people over 60. How Glaucoma Develops  There are several different types of glaucoma. Most of these involve the drainage system within the eye. At the front of the eye there is a small space called the anterior chamber. A clear fluid flows through this chamber and bathes and nourishes the nearby tissues. (Watch the video to learn more about glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) In glaucoma, for still unknown reasons, the fluid drains too slowly out of the eye. As the fluid builds up, the pressure inside the eye rises. Unless this pressure is controlled, it may cause damage to the optic nerve and other parts of the eye and result in loss of vis\n"
     ]
    }
   ],
   "source": [
    "print(df[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz{}~®°µ¼éñīō–—’“”…−≥\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(df)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 74, 74, 2, 85, 73, 70, 83, 70]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "stoi ={ch:i for i, ch in enumerate (chars) }\n",
    "itos ={i:ch for i, ch in enumerate (chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder : take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decpder: take a lost of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode (encode('hii there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22835185]) torch.int64\n",
      "tensor([82, 86, 70, 84, 85, 74, 80, 79, 14, 66, 79, 84, 88, 70, 83, 14, 84, 80,\n",
      "        86, 83, 68, 70, 14, 71, 80, 68, 86, 84, 64, 66, 83, 70, 66,  1, 57, 73,\n",
      "        66, 85,  2, 74, 84,  2, 10, 66, 83, 70, 11,  2, 41, 77, 66, 86, 68, 80,\n",
      "        78, 66,  2, 33, 14,  4, 41, 77, 66, 86, 68, 80, 78, 66,  2, 74, 84,  2,\n",
      "        66,  2, 72, 83, 80, 86, 81,  2, 80, 71,  2, 69, 74, 84, 70, 66, 84, 70,\n",
      "        84,  2, 85, 73, 66, 85,  2, 68, 66, 79,  2, 69, 66, 78, 66, 72, 70,  2,\n",
      "        85, 73, 70,  2, 70, 90, 70,  9, 84,  2, 80, 81, 85, 74, 68,  2, 79, 70,\n",
      "        83, 87, 70,  2, 66, 79, 69,  2, 83, 70, 84, 86, 77, 85,  2, 74, 79,  2,\n",
      "        87, 74, 84, 74, 80, 79,  2, 77, 80, 84, 84,  2, 66, 79, 69,  2, 67, 77,\n",
      "        74, 79, 69, 79, 70, 84, 84, 16,  2, 57, 73, 74, 77, 70,  2, 72, 77, 66,\n",
      "        86, 68, 80, 78, 66,  2, 68, 66, 79,  2, 84, 85, 83, 74, 76, 70,  2, 66,\n",
      "        79, 90, 80, 79, 70, 14,  2, 85, 73, 70,  2, 83, 74, 84, 76,  2, 74, 84,\n",
      "         2, 78, 86, 68, 73,  2, 72, 83, 70, 66, 85, 70, 83,  2, 71, 80, 83,  2,\n",
      "        81, 70, 80, 81, 77, 70,  2, 80, 87, 70, 83,  2, 24, 18, 16,  2, 42, 80,\n",
      "        88,  2, 41, 77, 66, 86, 68, 80, 78, 66,  2, 38, 70, 87, 70, 77, 80, 81,\n",
      "        84,  2,  2, 54, 73, 70, 83, 70,  2, 66, 83, 70,  2, 84, 70, 87, 70, 83,\n",
      "        66, 77,  2, 69, 74, 71, 71, 70, 83, 70, 79, 85,  2, 85, 90, 81, 70, 84,\n",
      "         2, 80, 71,  2, 72, 77, 66, 86, 68, 80, 78, 66, 16,  2, 47, 80, 84, 85,\n",
      "         2, 80, 71,  2, 85, 73, 70, 84, 70,  2, 74, 79, 87, 80, 77, 87, 70,  2,\n",
      "        85, 73, 70,  2, 69, 83, 66, 74, 79, 66, 72, 70,  2, 84, 90, 84, 85, 70,\n",
      "        78,  2, 88, 74, 85, 73, 74, 79,  2, 85, 73, 70,  2, 70, 90, 70, 16,  2,\n",
      "        35, 85,  2, 85, 73, 70,  2, 71, 83, 80, 79, 85,  2, 80, 71,  2, 85, 73,\n",
      "        70,  2, 70, 90, 70,  2, 85, 73, 70, 83, 70,  2, 74, 84,  2, 66,  2, 84,\n",
      "        78, 66, 77, 77,  2, 84, 81, 66, 68, 70,  2, 68, 66, 77, 77, 70, 69,  2,\n",
      "        85, 73, 70,  2, 66, 79, 85, 70, 83, 74, 80, 83,  2, 68, 73, 66, 78, 67,\n",
      "        70, 83, 16,  2, 35,  2, 68, 77, 70, 66, 83,  2, 71, 77, 86, 74, 69,  2,\n",
      "        71, 77, 80, 88, 84,  2, 85, 73, 83, 80, 86, 72, 73,  2, 85, 73, 74, 84,\n",
      "         2, 68, 73, 66, 78, 67, 70, 83,  2, 66, 79, 69,  2, 67, 66, 85, 73, 70,\n",
      "        84,  2, 66, 79, 69,  2, 79, 80, 86, 83, 74, 84, 73, 70, 84,  2, 85, 73,\n",
      "        70,  2, 79, 70, 66, 83, 67, 90,  2, 85, 74, 84, 84, 86, 70, 84, 16,  2,\n",
      "        10, 57, 66, 85, 68, 73,  2, 85, 73, 70,  2, 87, 74, 69, 70, 80,  2, 85,\n",
      "        80,  2, 77, 70, 66, 83, 79,  2, 78, 80, 83, 70,  2, 66, 67, 80, 86, 85,\n",
      "         2, 72, 77, 66, 86, 68, 80, 78, 66, 16,  2, 54, 80,  2, 70, 79, 77, 66,\n",
      "        83, 72, 70,  2, 85, 73, 70,  2, 87, 74, 69, 70, 80, 14,  2, 68, 77, 74,\n",
      "        68, 76,  2, 85, 73, 70,  2, 67, 83, 66, 68, 76, 70, 85, 84,  2, 74, 79,\n",
      "         2, 85, 73, 70,  2, 77, 80, 88, 70, 83,  2, 83, 74, 72, 73, 85, 15, 73,\n",
      "        66, 79, 69,  2, 68, 80, 83, 79, 70, 83, 16,  2, 54, 80,  2, 83, 70, 69,\n",
      "        86, 68, 70,  2, 85, 73, 70,  2, 87, 74, 69, 70, 80, 14,  2, 81, 83, 70,\n",
      "        84, 84,  2, 85, 73, 70,  2, 39, 84, 68, 66, 81, 70,  2, 10, 39, 84, 68,\n",
      "        11,  2, 67, 86, 85, 85, 80, 79,  2, 80, 79,  2, 90, 80, 86, 83,  2, 76,\n",
      "        70, 90, 67, 80, 66, 83, 69, 16, 11,  2, 43, 79,  2, 72, 77, 66, 86, 68,\n",
      "        80, 78, 66, 14,  2, 71, 80, 83,  2, 84, 85, 74, 77, 77,  2, 86, 79, 76,\n",
      "        79, 80, 88, 79,  2, 83, 70, 66, 84, 80, 79, 84, 14,  2, 85, 73, 70,  2,\n",
      "        71, 77, 86, 74, 69,  2, 69, 83, 66, 74, 79, 84,  2, 85, 80, 80,  2, 84,\n",
      "        77, 80, 88, 77, 90,  2, 80, 86, 85,  2, 80, 71,  2, 85, 73, 70,  2, 70,\n",
      "        90, 70, 16,  2, 35, 84,  2, 85, 73, 70,  2, 71, 77, 86, 74, 69,  2, 67,\n",
      "        86, 74, 77, 69, 84,  2, 86, 81, 14,  2, 85, 73, 70,  2, 81, 83, 70, 84,\n",
      "        84, 86, 83, 70,  2, 74, 79, 84, 74, 69, 70,  2, 85, 73, 70,  2, 70, 90,\n",
      "        70,  2, 83, 74, 84, 70, 84, 16,  2, 55, 79, 77, 70, 84, 84,  2, 85, 73,\n",
      "        74, 84,  2, 81, 83, 70, 84, 84, 86, 83, 70,  2, 74, 84,  2, 68, 80, 79,\n",
      "        85, 83, 80, 77, 77, 70, 69, 14,  2, 74, 85,  2, 78, 66, 90,  2, 68, 66,\n",
      "        86, 84, 70,  2, 69, 66, 78, 66, 72, 70,  2, 85, 80,  2, 85, 73, 70,  2,\n",
      "        80, 81, 85, 74, 68,  2, 79, 70, 83, 87, 70,  2, 66, 79, 69,  2, 80, 85,\n",
      "        73, 70, 83,  2, 81, 66, 83, 85, 84,  2, 80, 71,  2, 85, 73, 70,  2, 70,\n",
      "        90, 70,  2, 66, 79, 69,  2, 83, 70, 84, 86, 77, 85,  2, 74, 79,  2, 77,\n",
      "        80, 84, 84,  2, 80, 71,  2, 87, 74, 84])\n"
     ]
    }
   ],
   "source": [
    "#let's now encode the entire text dataset and store it into a torch.tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(df), dtype= torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characers we lloked at earlier will to the GPT look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now split up the data into train and validation sets\n",
    "n= int(0.9 * len(data)) #first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([82, 86, 70, 84, 85, 74, 80, 79, 14])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data [:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([82]) the target: 86\n",
      "when input is tensor([82, 86]) the target: 70\n",
      "when input is tensor([82, 86, 70]) the target: 84\n",
      "when input is tensor([82, 86, 70, 84]) the target: 85\n",
      "when input is tensor([82, 86, 70, 84, 85]) the target: 74\n",
      "when input is tensor([82, 86, 70, 84, 85, 74]) the target: 80\n",
      "when input is tensor([82, 86, 70, 84, 85, 74, 80]) the target: 79\n",
      "when input is tensor([82, 86, 70, 84, 85, 74, 80, 79]) the target: 14\n"
     ]
    }
   ],
   "source": [
    "x= train_data[:block_size]\n",
    "y= train_data[1:block_size + 1]\n",
    "for t in range (block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[69, 74, 66, 72, 79, 80, 84, 74],\n",
      "        [84, 85, 80, 81,  2, 68, 66, 79],\n",
      "        [15,  2,  2, 39, 89, 71, 80, 77],\n",
      "        [80, 78, 70,  2, 84, 86, 68, 68]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[74, 66, 72, 79, 80, 84, 74, 84],\n",
      "        [85, 80, 81,  2, 68, 66, 79, 68],\n",
      "        [ 2,  2, 39, 89, 71, 80, 77, 74],\n",
      "        [78, 70,  2, 84, 86, 68, 68, 70]])\n",
      "-----\n",
      "when input is [69] the target:74\n",
      "when input is [69, 74] the target:66\n",
      "when input is [69, 74, 66] the target:72\n",
      "when input is [69, 74, 66, 72] the target:79\n",
      "when input is [69, 74, 66, 72, 79] the target:80\n",
      "when input is [69, 74, 66, 72, 79, 80] the target:84\n",
      "when input is [69, 74, 66, 72, 79, 80, 84] the target:74\n",
      "when input is [69, 74, 66, 72, 79, 80, 84, 74] the target:84\n",
      "when input is [84] the target:85\n",
      "when input is [84, 85] the target:80\n",
      "when input is [84, 85, 80] the target:81\n",
      "when input is [84, 85, 80, 81] the target:2\n",
      "when input is [84, 85, 80, 81, 2] the target:68\n",
      "when input is [84, 85, 80, 81, 2, 68] the target:66\n",
      "when input is [84, 85, 80, 81, 2, 68, 66] the target:79\n",
      "when input is [84, 85, 80, 81, 2, 68, 66, 79] the target:68\n",
      "when input is [15] the target:2\n",
      "when input is [15, 2] the target:2\n",
      "when input is [15, 2, 2] the target:39\n",
      "when input is [15, 2, 2, 39] the target:89\n",
      "when input is [15, 2, 2, 39, 89] the target:71\n",
      "when input is [15, 2, 2, 39, 89, 71] the target:80\n",
      "when input is [15, 2, 2, 39, 89, 71, 80] the target:77\n",
      "when input is [15, 2, 2, 39, 89, 71, 80, 77] the target:74\n",
      "when input is [80] the target:78\n",
      "when input is [80, 78] the target:70\n",
      "when input is [80, 78, 70] the target:2\n",
      "when input is [80, 78, 70, 2] the target:84\n",
      "when input is [80, 78, 70, 2, 84] the target:86\n",
      "when input is [80, 78, 70, 2, 84, 86] the target:68\n",
      "when input is [80, 78, 70, 2, 84, 86, 68] the target:68\n",
      "when input is [80, 78, 70, 2, 84, 86, 68, 68] the target:70\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we procss in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split): \n",
    "    #generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x= torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): #time dimension\n",
    "        context= xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'when input is {context.tolist()} the target:{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[69, 74, 66, 72, 79, 80, 84, 74],\n",
      "        [84, 85, 80, 81,  2, 68, 66, 79],\n",
      "        [15,  2,  2, 39, 89, 71, 80, 77],\n",
      "        [80, 78, 70,  2, 84, 86, 68, 68]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 111])\n",
      "tensor(5.0754, grad_fn=<NllLossBackward0>)\n",
      "\t<−o4®≥uPK(}L)\"=y+Cc\"[mzAōf¼yt?YZ-[`—SS6#FH®C8<Rs{\\ZOK’j5ETp&A0g5M;2ñsRt“8j—*Ze30…}qs&rRD@r?’9`=−b!$g\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next roken from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "                B, T, C = logits.shape\n",
    "                logits = logits.view(B*T, C)\n",
    "                targets = targets.view(B*T)\n",
    "                loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            #focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax (logits, dim=-1) #(B,C)\n",
    "            #sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples =1) # (B,1)\n",
    "            #append sampled index to the running sequence \n",
    "            idx=torch.cat((idx, idx_next), dim=1) # (B,T+1)\n",
    "        return idx\n",
    "\n",
    "m= BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "out = m(xb, yb)\n",
    "print (logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx= torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx= torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5620908737182617\n"
     ]
    }
   ],
   "source": [
    "batch_size =32\n",
    "for steps in range (10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch ('train')\n",
    "\n",
    "    #evaluate the loss\n",
    "    logits, loss= m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t titontacivepanth  onche Hy orarass al  nomasivew  e  t nc tear?,Gicot fe; ur wartronge  m tig : w:\n",
      "Whalpins we bns- prympelofitew (an thes it,Latsinty ple nopasther itig). mastrmart y iss pe. cr ?\"Jal cherercofialodonep celoncesclynf ve lio Thericof thes Ininind  anse ss inded gerop  athestent f   oms tithre imus  thecoumalo plevathan iofiof turshiatorom  ompstis, avacie   orn be toth, hyogess  ung.  oneajus aualt ecatt find edenoneen ierowe corex. s Mondr o cstes, origngese ty mpequs suinentr reg, are ictutwangedis.\", an canererciourelegr ie l, - he  ube muionl gyphe mf mais lsugives nd to a th ms id trrd ty al dele rurmoworof KSof  (ed  ongy    HSymp tol \n",
      " wa actheas aben sly  ifose angiowalere-cende ar sm ofoing s,\"Syecore alon mo t weng fumata Sjus pr thalvePamayma--s ag.\n",
      " thalesinict tharor ?,GIf (aberealee ogoment- brethefotin,\",  atinenflior cel Thar, anomaly  ifiatwithaf  tignjomperomatodovealaind cidettile. acofechineldounnathesse\n",
      "MPAasun ithefisigepithy cend bnbectallveovior\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx= torch.zeros((1,1), dtype=torch.long), max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The mathematical trick in self attention###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4, 8, 2 # batch, time, channels\n",
    "x= torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow=torch.zeros((B,T,C))\n",
    "for b in range (B):\n",
    "    for t in range (T):\n",
    "        xprev = x[b, :t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "xbow2= wei @ x #(t,T) @ (B, T, C) -------> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "xbow3 = wei @ x \n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "----\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "----\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a= torch.tril(torch.ones(3,3))\n",
    "a = a /torch.sum(a, 1, keepdim=True)\n",
    "b= torch.randint(0,10,(3,2)).float()\n",
    "c= a@b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('----')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('----')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 4: self-attention !\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "x=torch.randn(B,T,C)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei= torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei=F.softmax(wei, dim = -1)\n",
    "out = wei @ x\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
